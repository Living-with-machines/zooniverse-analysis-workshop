{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Zooniverse workflow-specific classification and subject records into a single CSV with anonymised PII\n",
    "\n",
    "This Notebook is designed for Zooniverse project owners who want to process classification (annotation) data and subject records in a single CSV file. It will also replace volunteer usernames, IP addresses and user IDs with a pseudononymous identifier, so that the CSV file can be publically shared without personally identifiable information (PII).\n",
    "\n",
    "The Notebook can be used with workflow-specific classification files or the general classification file which contains annotations from all tasks. This code is not optimised for very large files but has been tested on files with c 8000 classifications.\n",
    "\n",
    "Start by exporting your classification and subject files from Zooniverse, and saving them somewhere that the Notebook can access them (see below).\n",
    "\n",
    "This Notebook reads Zooniverse classification and subject CSV files and performs the following tasks:\n",
    "\n",
    "1. It combines the information from:  \n",
    "    (a) the **classifications** file, which contains all the annotations users have provided for a given workflow's subjects, with  \n",
    "    (b) the information from the **subjects** file, which documents the information about the subjects (items) annotated in specific tasks.\n",
    "\n",
    "2. It processes the columns that contain information in JSON format and transforms them (and the rest of the data) into spreadsheet columns for ease of use. \n",
    "\n",
    "3. It removes any Personally Identifiable Information, such as usernames and IP addresses.\n",
    "\n",
    "4. It produces a .csv file that can be opened in any spreadsheet tool (Microsoft Excel, Apple Numbers, etc.) for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting set up\n",
    "\n",
    "In the next cell, you will specify where the data that you want to process is located. These should be two paths on your drive, which can be _relative_ (to where this notebook is located) or _absolute_ (a specified full path to each file).\n",
    "\n",
    "#### Example 1: Sample data\n",
    "\n",
    "If you do not have any downloaded data, but want to use the sample data that we have provided (located in the same folder as this notebook), you should put these two _relative_ paths in the next cell:\n",
    "\n",
    "```py\n",
    "classifications_file = \"sample_data/test_classifications.csv\"\n",
    "subjects_file = \"sample_data/test_subjects.csv\"\n",
    "```\n",
    "\n",
    "Pandas is a very flexible Python package, which can also accept valid URLs, so you could also write:\n",
    "\n",
    "```py\n",
    "classifications_file = \"https://raw.githubusercontent.com/Living-with-machines/zooniverse-analysis-workshop/main/sample_data/test_classifications.csv\"\n",
    "subjects_file = \"https://raw.githubusercontent.com/Living-with-machines/zooniverse-analysis-workshop/main/sample_data/test_subjects.csv\"\n",
    "```\n",
    "\n",
    "#### Example 2: Downloaded data in Downloads folder\n",
    "\n",
    "If you have downloaded the files as `classifications.csv` and `subjects.csv` on a Mac and they are located in your `Downloads` folder, in the next cell you would put two _absolute_ paths:\n",
    "\n",
    "```py\n",
    "classifications_file = \"/Users/<your-username>/Downloads/classifications.csv\"\n",
    "subjects_file = \"/Users/<your-username>/Downloads/subjects.csv\"\n",
    "```\n",
    "\n",
    "\n",
    "#### Example 3: Data in your Google Drive\n",
    "\n",
    "```py\n",
    "# Code originally from https://github.com/kingsdigitallab/lwm-davizct\n",
    "# Update the paths to match the location of files on your Google Drive\n",
    "# Running this code will trigger a dialogue to allow access to your Google Drive\n",
    "ipython = get_ipython()\n",
    "IN_COLAB = \"google.colab\" in str(ipython)\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    data_path = \"drive/My Drive/Zooniverse_exports\"\n",
    "    sources_path = \"drive/My Drive/Zooniverse_exports\" # not needed in this notebook?\n",
    "    subjects_path = \"drive/My Drive/Zooniverse_exports\" # not needed in this notebook?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now it is your turn!\n",
    "\n",
    "**Fill in the file locations in this cell:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_file = \"/Users/mridge/Desktop/Zooniverse_data_downloads_20230922/living-with-machines-classifications.csv\"\n",
    "subjects_file = \"/Users/mridge/Desktop/Zooniverse_data_downloads_20230922/living-with-machines-subjects.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our definitions\n",
    "\n",
    "**Now, we are ready to get started working with our data.**\n",
    "\n",
    "First, we need to import the packages that we are going to use in the script below. Most of them are built-in to Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import ChainMap\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our main data\n",
    "\n",
    "Next, it's time to read in the main CSV data as a pandas DataFrame, using the handy method `.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(classifications_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a handy method to look at the data that we have just imported, called `.head(num)`, where `num` should be replaced with the amount of rows in the frame that you want to see.\n",
    "\n",
    "We run it below to see what our imported data looks like unprocessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_name</th>\n",
       "      <th>workflow_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>expert</th>\n",
       "      <th>metadata</th>\n",
       "      <th>annotations</th>\n",
       "      <th>subject_data</th>\n",
       "      <th>subject_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182764251</td>\n",
       "      <td>BLDigital</td>\n",
       "      <td>1744856.0</td>\n",
       "      <td>a1101d7a939fa11891dd</td>\n",
       "      <td>12038</td>\n",
       "      <td>Classify and summarise articles (set 1)</td>\n",
       "      <td>16.37</td>\n",
       "      <td>2019-09-12 14:14:53 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"5ae397cb5b23d52e566...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Does this article ...</td>\n",
       "      <td>{\"36628096\":{\"retired\":null,\"!page\":\"0001\",\"!i...</td>\n",
       "      <td>36628096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182765789</td>\n",
       "      <td>BLDigital</td>\n",
       "      <td>1744856.0</td>\n",
       "      <td>a1101d7a939fa11891dd</td>\n",
       "      <td>12038</td>\n",
       "      <td>Classify and summarise articles (set 1)</td>\n",
       "      <td>17.38</td>\n",
       "      <td>2019-09-12 14:19:12 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"cf9b4c60343be171828...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Does this article ...</td>\n",
       "      <td>{\"36627906\":{\"retired\":null,\"!page\":\"0006\",\"!i...</td>\n",
       "      <td>36627906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182772640</td>\n",
       "      <td>BLDigital</td>\n",
       "      <td>1744856.0</td>\n",
       "      <td>a1101d7a939fa11891dd</td>\n",
       "      <td>12051</td>\n",
       "      <td>Classify articles (set 2)</td>\n",
       "      <td>9.80</td>\n",
       "      <td>2019-09-12 14:36:11 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"4c47f81a0f62a51a2b6...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Does this article ...</td>\n",
       "      <td>{\"36695806\":{\"retired\":null,\"!page\":\"0008\",\"!i...</td>\n",
       "      <td>36695806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classification_id  user_name    user_id               user_ip  workflow_id  \\\n",
       "0          182764251  BLDigital  1744856.0  a1101d7a939fa11891dd        12038   \n",
       "1          182765789  BLDigital  1744856.0  a1101d7a939fa11891dd        12038   \n",
       "2          182772640  BLDigital  1744856.0  a1101d7a939fa11891dd        12051   \n",
       "\n",
       "                             workflow_name  workflow_version  \\\n",
       "0  Classify and summarise articles (set 1)             16.37   \n",
       "1  Classify and summarise articles (set 1)             17.38   \n",
       "2                Classify articles (set 2)              9.80   \n",
       "\n",
       "                created_at  gold_standard  expert  \\\n",
       "0  2019-09-12 14:14:53 UTC            NaN     NaN   \n",
       "1  2019-09-12 14:19:12 UTC            NaN     NaN   \n",
       "2  2019-09-12 14:36:11 UTC            NaN     NaN   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"source\":\"api\",\"session\":\"5ae397cb5b23d52e566...   \n",
       "1  {\"source\":\"api\",\"session\":\"cf9b4c60343be171828...   \n",
       "2  {\"source\":\"api\",\"session\":\"4c47f81a0f62a51a2b6...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{\"task\":\"T0\",\"task_label\":\"Does this article ...   \n",
       "1  [{\"task\":\"T0\",\"task_label\":\"Does this article ...   \n",
       "2  [{\"task\":\"T0\",\"task_label\":\"Does this article ...   \n",
       "\n",
       "                                        subject_data  subject_ids  \n",
       "0  {\"36628096\":{\"retired\":null,\"!page\":\"0001\",\"!i...     36628096  \n",
       "1  {\"36627906\":{\"retired\":null,\"!page\":\"0006\",\"!i...     36627906  \n",
       "2  {\"36695806\":{\"retired\":null,\"!page\":\"0008\",\"!i...     36695806  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in our preview, the `classification_id` is a column, which is unique for each classification. It can thus be used as an \"index\" for the DataFrame, a nice way of querying the frame by individual IDs.\n",
    "\n",
    "Here's how we can set the index on our `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"classification_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Python and Pandas are both \"succeeding silently\", it can be good to sometimes have what we call a \"reality check\" to ensure that we have the result that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_ip</th>\n",
       "      <th>workflow_id</th>\n",
       "      <th>workflow_name</th>\n",
       "      <th>workflow_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>expert</th>\n",
       "      <th>metadata</th>\n",
       "      <th>annotations</th>\n",
       "      <th>subject_data</th>\n",
       "      <th>subject_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182764251</th>\n",
       "      <td>BLDigital</td>\n",
       "      <td>1744856.0</td>\n",
       "      <td>a1101d7a939fa11891dd</td>\n",
       "      <td>12038</td>\n",
       "      <td>Classify and summarise articles (set 1)</td>\n",
       "      <td>16.37</td>\n",
       "      <td>2019-09-12 14:14:53 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"5ae397cb5b23d52e566...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Does this article ...</td>\n",
       "      <td>{\"36628096\":{\"retired\":null,\"!page\":\"0001\",\"!i...</td>\n",
       "      <td>36628096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182765789</th>\n",
       "      <td>BLDigital</td>\n",
       "      <td>1744856.0</td>\n",
       "      <td>a1101d7a939fa11891dd</td>\n",
       "      <td>12038</td>\n",
       "      <td>Classify and summarise articles (set 1)</td>\n",
       "      <td>17.38</td>\n",
       "      <td>2019-09-12 14:19:12 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"cf9b4c60343be171828...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Does this article ...</td>\n",
       "      <td>{\"36627906\":{\"retired\":null,\"!page\":\"0006\",\"!i...</td>\n",
       "      <td>36627906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182772640</th>\n",
       "      <td>BLDigital</td>\n",
       "      <td>1744856.0</td>\n",
       "      <td>a1101d7a939fa11891dd</td>\n",
       "      <td>12051</td>\n",
       "      <td>Classify articles (set 2)</td>\n",
       "      <td>9.80</td>\n",
       "      <td>2019-09-12 14:36:11 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"source\":\"api\",\"session\":\"4c47f81a0f62a51a2b6...</td>\n",
       "      <td>[{\"task\":\"T0\",\"task_label\":\"Does this article ...</td>\n",
       "      <td>{\"36695806\":{\"retired\":null,\"!page\":\"0008\",\"!i...</td>\n",
       "      <td>36695806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_name    user_id               user_ip  workflow_id  \\\n",
       "classification_id                                                            \n",
       "182764251          BLDigital  1744856.0  a1101d7a939fa11891dd        12038   \n",
       "182765789          BLDigital  1744856.0  a1101d7a939fa11891dd        12038   \n",
       "182772640          BLDigital  1744856.0  a1101d7a939fa11891dd        12051   \n",
       "\n",
       "                                             workflow_name  workflow_version  \\\n",
       "classification_id                                                              \n",
       "182764251          Classify and summarise articles (set 1)             16.37   \n",
       "182765789          Classify and summarise articles (set 1)             17.38   \n",
       "182772640                        Classify articles (set 2)              9.80   \n",
       "\n",
       "                                created_at  gold_standard  expert  \\\n",
       "classification_id                                                   \n",
       "182764251          2019-09-12 14:14:53 UTC            NaN     NaN   \n",
       "182765789          2019-09-12 14:19:12 UTC            NaN     NaN   \n",
       "182772640          2019-09-12 14:36:11 UTC            NaN     NaN   \n",
       "\n",
       "                                                            metadata  \\\n",
       "classification_id                                                      \n",
       "182764251          {\"source\":\"api\",\"session\":\"5ae397cb5b23d52e566...   \n",
       "182765789          {\"source\":\"api\",\"session\":\"cf9b4c60343be171828...   \n",
       "182772640          {\"source\":\"api\",\"session\":\"4c47f81a0f62a51a2b6...   \n",
       "\n",
       "                                                         annotations  \\\n",
       "classification_id                                                      \n",
       "182764251          [{\"task\":\"T0\",\"task_label\":\"Does this article ...   \n",
       "182765789          [{\"task\":\"T0\",\"task_label\":\"Does this article ...   \n",
       "182772640          [{\"task\":\"T0\",\"task_label\":\"Does this article ...   \n",
       "\n",
       "                                                        subject_data  \\\n",
       "classification_id                                                      \n",
       "182764251          {\"36628096\":{\"retired\":null,\"!page\":\"0001\",\"!i...   \n",
       "182765789          {\"36627906\":{\"retired\":null,\"!page\":\"0006\",\"!i...   \n",
       "182772640          {\"36695806\":{\"retired\":null,\"!page\":\"0008\",\"!i...   \n",
       "\n",
       "                   subject_ids  \n",
       "classification_id               \n",
       "182764251             36628096  \n",
       "182765789             36627906  \n",
       "182772640             36695806  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure correct encoding\n",
    "\n",
    "Next, we will want to have a look at the encoding of each column.\n",
    "\n",
    "In the \"reality check\" above, you can see that the columns `subject_data`, `annotations`, and `metadata` are structured as JSON (JavaScript Object Notation), which the DataFrame parser cannot interpret on its own, which is why we have to help it using the following parsing of those specific columns.\n",
    "\n",
    "If you use Pandas' `.apply()` method (which can be applied on a column or on the entire DataFrame), you can help the software interpret the data in the columns. Here, we pass a function (`json.loads`, i.e. the `loads` function from Python's built-in `json` package) to each of the columns containing JSON data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"metadata\"] = df[\"metadata\"].apply(json.loads)\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we might want to do a \"reality check\". To look at a specific part of a dataframe we can \"slice it\" by passing it a list (note the double `[[` and `]]` on each side of the selector) of the columns we want to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotations</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182764251</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'Does this artic...</td>\n",
       "      <td>{'source': 'api', 'session': '5ae397cb5b23d52e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182765789</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'Does this artic...</td>\n",
       "      <td>{'source': 'api', 'session': 'cf9b4c60343be171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182772640</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'Does this artic...</td>\n",
       "      <td>{'source': 'api', 'session': '4c47f81a0f62a51a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182773477</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'Does this artic...</td>\n",
       "      <td>{'source': 'api', 'session': '9a94c60ab0d0adf2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182775776</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'Does this artic...</td>\n",
       "      <td>{'source': 'api', 'session': 'c3057982c76d2876...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494468187</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'We searched for...</td>\n",
       "      <td>{'source': 'api', 'session': '811fa5b5f2675989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494468312</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'We searched for...</td>\n",
       "      <td>{'source': 'api', 'session': '811fa5b5f2675989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494468466</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'We searched for...</td>\n",
       "      <td>{'source': 'api', 'session': '811fa5b5f2675989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494468760</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'We searched for...</td>\n",
       "      <td>{'source': 'api', 'session': '811fa5b5f2675989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494468789</th>\n",
       "      <td>[{'task': 'T0', 'task_label': 'We searched for...</td>\n",
       "      <td>{'source': 'api', 'session': '811fa5b5f2675989...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         annotations  \\\n",
       "classification_id                                                      \n",
       "182764251          [{'task': 'T0', 'task_label': 'Does this artic...   \n",
       "182765789          [{'task': 'T0', 'task_label': 'Does this artic...   \n",
       "182772640          [{'task': 'T0', 'task_label': 'Does this artic...   \n",
       "182773477          [{'task': 'T0', 'task_label': 'Does this artic...   \n",
       "182775776          [{'task': 'T0', 'task_label': 'Does this artic...   \n",
       "...                                                              ...   \n",
       "494468187          [{'task': 'T0', 'task_label': 'We searched for...   \n",
       "494468312          [{'task': 'T0', 'task_label': 'We searched for...   \n",
       "494468466          [{'task': 'T0', 'task_label': 'We searched for...   \n",
       "494468760          [{'task': 'T0', 'task_label': 'We searched for...   \n",
       "494468789          [{'task': 'T0', 'task_label': 'We searched for...   \n",
       "\n",
       "                                                            metadata  \n",
       "classification_id                                                     \n",
       "182764251          {'source': 'api', 'session': '5ae397cb5b23d52e...  \n",
       "182765789          {'source': 'api', 'session': 'cf9b4c60343be171...  \n",
       "182772640          {'source': 'api', 'session': '4c47f81a0f62a51a...  \n",
       "182773477          {'source': 'api', 'session': '9a94c60ab0d0adf2...  \n",
       "182775776          {'source': 'api', 'session': 'c3057982c76d2876...  \n",
       "...                                                              ...  \n",
       "494468187          {'source': 'api', 'session': '811fa5b5f2675989...  \n",
       "494468312          {'source': 'api', 'session': '811fa5b5f2675989...  \n",
       "494468466          {'source': 'api', 'session': '811fa5b5f2675989...  \n",
       "494468760          {'source': 'api', 'session': '811fa5b5f2675989...  \n",
       "494468789          {'source': 'api', 'session': '811fa5b5f2675989...  \n",
       "\n",
       "[255840 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"annotations\", \"metadata\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "In the following two sections, we will process the `metadata`, and `annotations` column respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract classification metadata (`metadata`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to do something similar to what we did with the subjects above to process the metadata for each classification.\n",
    "\n",
    "Because the data in the `metadata` column has nested JSON data (that is, objects and lists that are wrapped inside each other), we want to use the particular `json_normalize` method.\n",
    "\n",
    "Here's an example of what one `metadata` row looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'api',\n",
       " 'session': '5ae397cb5b23d52e566a93b9db18d40385b9e2a54a5bc21a5dc0670947b71eb2',\n",
       " 'viewport': {'width': 1366, 'height': 654},\n",
       " 'started_at': '2019-09-12T14:14:36.447Z',\n",
       " 'user_agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0',\n",
       " 'utc_offset': '-3600',\n",
       " 'finished_at': '2019-09-12T14:14:53.177Z',\n",
       " 'live_project': False,\n",
       " 'interventions': {'opt_in': True, 'messageShown': False},\n",
       " 'user_language': 'en',\n",
       " 'user_group_ids': [],\n",
       " 'subject_dimensions': [{'clientWidth': 634,\n",
       "   'clientHeight': 72,\n",
       "   'naturalWidth': 634,\n",
       "   'naturalHeight': 72}],\n",
       " 'subject_selection_state': {'retired': False,\n",
       "  'selected_at': '2019-09-12T14:14:36.224Z',\n",
       "  'already_seen': False,\n",
       "  'selection_state': 'normal',\n",
       "  'finished_workflow': False,\n",
       "  'user_has_finished_workflow': False},\n",
       " 'workflow_translation_id': '24214'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.metadata[df.metadata.head(1).index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a separate DataFrame from the normalised JSON data in the columns using the json_normalize method and use `.head()` to see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>session</th>\n",
       "      <th>started_at</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>live_project</th>\n",
       "      <th>user_language</th>\n",
       "      <th>user_group_ids</th>\n",
       "      <th>subject_dimensions</th>\n",
       "      <th>...</th>\n",
       "      <th>viewport.height</th>\n",
       "      <th>interventions.opt_in</th>\n",
       "      <th>interventions.messageShown</th>\n",
       "      <th>subject_selection_state.retired</th>\n",
       "      <th>subject_selection_state.selected_at</th>\n",
       "      <th>subject_selection_state.already_seen</th>\n",
       "      <th>subject_selection_state.selection_state</th>\n",
       "      <th>subject_selection_state.finished_workflow</th>\n",
       "      <th>subject_selection_state.user_has_finished_workflow</th>\n",
       "      <th>seen_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>api</td>\n",
       "      <td>5ae397cb5b23d52e566a93b9db18d40385b9e2a54a5bc2...</td>\n",
       "      <td>2019-09-12T14:14:36.447Z</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...</td>\n",
       "      <td>-3600</td>\n",
       "      <td>2019-09-12T14:14:53.177Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'clientWidth': 634, 'clientHeight': 72, 'nat...</td>\n",
       "      <td>...</td>\n",
       "      <td>654.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-09-12T14:14:36.224Z</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>api</td>\n",
       "      <td>cf9b4c60343be1718280b5dfeb8e4558398704aad25c7b...</td>\n",
       "      <td>2019-09-12T14:18:26.521Z</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...</td>\n",
       "      <td>-3600</td>\n",
       "      <td>2019-09-12T14:19:11.829Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'clientWidth': 816, 'clientHeight': 440, 'na...</td>\n",
       "      <td>...</td>\n",
       "      <td>654.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-09-12T14:18:26.462Z</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>api</td>\n",
       "      <td>4c47f81a0f62a51a2b6b45be1efb1cc26da9a87cd4a7e0...</td>\n",
       "      <td>2019-09-12T14:35:46.499Z</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...</td>\n",
       "      <td>-3600</td>\n",
       "      <td>2019-09-12T14:36:11.339Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'clientWidth': 388, 'clientHeight': 589, 'na...</td>\n",
       "      <td>...</td>\n",
       "      <td>654.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-09-12T14:35:46.342Z</td>\n",
       "      <td>False</td>\n",
       "      <td>internal_fallback</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                            session  \\\n",
       "0    api  5ae397cb5b23d52e566a93b9db18d40385b9e2a54a5bc2...   \n",
       "1    api  cf9b4c60343be1718280b5dfeb8e4558398704aad25c7b...   \n",
       "2    api  4c47f81a0f62a51a2b6b45be1efb1cc26da9a87cd4a7e0...   \n",
       "\n",
       "                 started_at  \\\n",
       "0  2019-09-12T14:14:36.447Z   \n",
       "1  2019-09-12T14:18:26.521Z   \n",
       "2  2019-09-12T14:35:46.499Z   \n",
       "\n",
       "                                          user_agent utc_offset  \\\n",
       "0  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...      -3600   \n",
       "1  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...      -3600   \n",
       "2  Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...      -3600   \n",
       "\n",
       "                finished_at  live_project user_language user_group_ids  \\\n",
       "0  2019-09-12T14:14:53.177Z         False            en             []   \n",
       "1  2019-09-12T14:19:11.829Z         False            en             []   \n",
       "2  2019-09-12T14:36:11.339Z         False            en             []   \n",
       "\n",
       "                                  subject_dimensions  ... viewport.height  \\\n",
       "0  [{'clientWidth': 634, 'clientHeight': 72, 'nat...  ...           654.0   \n",
       "1  [{'clientWidth': 816, 'clientHeight': 440, 'na...  ...           654.0   \n",
       "2  [{'clientWidth': 388, 'clientHeight': 589, 'na...  ...           654.0   \n",
       "\n",
       "   interventions.opt_in  interventions.messageShown  \\\n",
       "0                  True                       False   \n",
       "1                  True                       False   \n",
       "2                  True                       False   \n",
       "\n",
       "  subject_selection_state.retired subject_selection_state.selected_at  \\\n",
       "0                           False            2019-09-12T14:14:36.224Z   \n",
       "1                           False            2019-09-12T14:18:26.462Z   \n",
       "2                           False            2019-09-12T14:35:46.342Z   \n",
       "\n",
       "  subject_selection_state.already_seen  \\\n",
       "0                                False   \n",
       "1                                False   \n",
       "2                                False   \n",
       "\n",
       "  subject_selection_state.selection_state  \\\n",
       "0                                  normal   \n",
       "1                                  normal   \n",
       "2                       internal_fallback   \n",
       "\n",
       "  subject_selection_state.finished_workflow  \\\n",
       "0                                     False   \n",
       "1                                     False   \n",
       "2                                     False   \n",
       "\n",
       "  subject_selection_state.user_has_finished_workflow seen_before  \n",
       "0                                              False         NaN  \n",
       "1                                              False         NaN  \n",
       "2                                              False         NaN  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata = pd.json_normalize(df[\"metadata\"])\n",
    "\n",
    "df_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the shape of the classification metadata DataFrame (`df_metadata`) and the main classification DataFrame (`df`) are the same, we can apply the `set_index` method to the metadata to get the `classification_id` as index on the `df_metadata`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.set_index(df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reality check time again — good practice, keep track of what you're doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>session</th>\n",
       "      <th>started_at</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>utc_offset</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>live_project</th>\n",
       "      <th>user_language</th>\n",
       "      <th>user_group_ids</th>\n",
       "      <th>subject_dimensions</th>\n",
       "      <th>...</th>\n",
       "      <th>viewport.height</th>\n",
       "      <th>interventions.opt_in</th>\n",
       "      <th>interventions.messageShown</th>\n",
       "      <th>subject_selection_state.retired</th>\n",
       "      <th>subject_selection_state.selected_at</th>\n",
       "      <th>subject_selection_state.already_seen</th>\n",
       "      <th>subject_selection_state.selection_state</th>\n",
       "      <th>subject_selection_state.finished_workflow</th>\n",
       "      <th>subject_selection_state.user_has_finished_workflow</th>\n",
       "      <th>seen_before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182764251</th>\n",
       "      <td>api</td>\n",
       "      <td>5ae397cb5b23d52e566a93b9db18d40385b9e2a54a5bc2...</td>\n",
       "      <td>2019-09-12T14:14:36.447Z</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...</td>\n",
       "      <td>-3600</td>\n",
       "      <td>2019-09-12T14:14:53.177Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'clientWidth': 634, 'clientHeight': 72, 'nat...</td>\n",
       "      <td>...</td>\n",
       "      <td>654.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-09-12T14:14:36.224Z</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182765789</th>\n",
       "      <td>api</td>\n",
       "      <td>cf9b4c60343be1718280b5dfeb8e4558398704aad25c7b...</td>\n",
       "      <td>2019-09-12T14:18:26.521Z</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...</td>\n",
       "      <td>-3600</td>\n",
       "      <td>2019-09-12T14:19:11.829Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'clientWidth': 816, 'clientHeight': 440, 'na...</td>\n",
       "      <td>...</td>\n",
       "      <td>654.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-09-12T14:18:26.462Z</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182772640</th>\n",
       "      <td>api</td>\n",
       "      <td>4c47f81a0f62a51a2b6b45be1efb1cc26da9a87cd4a7e0...</td>\n",
       "      <td>2019-09-12T14:35:46.499Z</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...</td>\n",
       "      <td>-3600</td>\n",
       "      <td>2019-09-12T14:36:11.339Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'clientWidth': 388, 'clientHeight': 589, 'na...</td>\n",
       "      <td>...</td>\n",
       "      <td>654.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-09-12T14:35:46.342Z</td>\n",
       "      <td>False</td>\n",
       "      <td>internal_fallback</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source                                            session  \\\n",
       "classification_id                                                             \n",
       "182764251            api  5ae397cb5b23d52e566a93b9db18d40385b9e2a54a5bc2...   \n",
       "182765789            api  cf9b4c60343be1718280b5dfeb8e4558398704aad25c7b...   \n",
       "182772640            api  4c47f81a0f62a51a2b6b45be1efb1cc26da9a87cd4a7e0...   \n",
       "\n",
       "                                 started_at  \\\n",
       "classification_id                             \n",
       "182764251          2019-09-12T14:14:36.447Z   \n",
       "182765789          2019-09-12T14:18:26.521Z   \n",
       "182772640          2019-09-12T14:35:46.499Z   \n",
       "\n",
       "                                                          user_agent  \\\n",
       "classification_id                                                      \n",
       "182764251          Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...   \n",
       "182765789          Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...   \n",
       "182772640          Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69...   \n",
       "\n",
       "                  utc_offset               finished_at  live_project  \\\n",
       "classification_id                                                      \n",
       "182764251              -3600  2019-09-12T14:14:53.177Z         False   \n",
       "182765789              -3600  2019-09-12T14:19:11.829Z         False   \n",
       "182772640              -3600  2019-09-12T14:36:11.339Z         False   \n",
       "\n",
       "                  user_language user_group_ids  \\\n",
       "classification_id                                \n",
       "182764251                    en             []   \n",
       "182765789                    en             []   \n",
       "182772640                    en             []   \n",
       "\n",
       "                                                  subject_dimensions  ...  \\\n",
       "classification_id                                                     ...   \n",
       "182764251          [{'clientWidth': 634, 'clientHeight': 72, 'nat...  ...   \n",
       "182765789          [{'clientWidth': 816, 'clientHeight': 440, 'na...  ...   \n",
       "182772640          [{'clientWidth': 388, 'clientHeight': 589, 'na...  ...   \n",
       "\n",
       "                  viewport.height  interventions.opt_in  \\\n",
       "classification_id                                         \n",
       "182764251                   654.0                  True   \n",
       "182765789                   654.0                  True   \n",
       "182772640                   654.0                  True   \n",
       "\n",
       "                   interventions.messageShown subject_selection_state.retired  \\\n",
       "classification_id                                                               \n",
       "182764251                               False                           False   \n",
       "182765789                               False                           False   \n",
       "182772640                               False                           False   \n",
       "\n",
       "                  subject_selection_state.selected_at  \\\n",
       "classification_id                                       \n",
       "182764251                    2019-09-12T14:14:36.224Z   \n",
       "182765789                    2019-09-12T14:18:26.462Z   \n",
       "182772640                    2019-09-12T14:35:46.342Z   \n",
       "\n",
       "                  subject_selection_state.already_seen  \\\n",
       "classification_id                                        \n",
       "182764251                                        False   \n",
       "182765789                                        False   \n",
       "182772640                                        False   \n",
       "\n",
       "                  subject_selection_state.selection_state  \\\n",
       "classification_id                                           \n",
       "182764251                                          normal   \n",
       "182765789                                          normal   \n",
       "182772640                               internal_fallback   \n",
       "\n",
       "                  subject_selection_state.finished_workflow  \\\n",
       "classification_id                                             \n",
       "182764251                                             False   \n",
       "182765789                                             False   \n",
       "182772640                                             False   \n",
       "\n",
       "                  subject_selection_state.user_has_finished_workflow  \\\n",
       "classification_id                                                      \n",
       "182764251                                                      False   \n",
       "182765789                                                      False   \n",
       "182772640                                                      False   \n",
       "\n",
       "                  seen_before  \n",
       "classification_id              \n",
       "182764251                 NaN  \n",
       "182765789                 NaN  \n",
       "182772640                 NaN  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract annotations (`annotations`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final information we want to extract and process from the main DataFrame are the annotations for each classification.\n",
    "\n",
    "In order to do so, we must first preprocess the JSON data that we have available, extracting a list of only the information we want (the \"annotation values\"). We set up a function that processes each individual row, and then apply it to each row, using the `.apply` method, which we have used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotation_values(annotation_row):\n",
    "    \"\"\"\n",
    "    Takes an annotation row, which contains a list of tasks with values in dictionary {task, task_label, value}\n",
    "    and extracts the `value` for each `task`, disregarding the `task_label` and returns them as a dictionary,\n",
    "    for easy insertion into a DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    extracted_dictionaries = [{task_data.get('task'): task_data.get('value')} for task_data in annotation_row]\n",
    "    return dict(ChainMap(*extracted_dictionaries))\n",
    "\n",
    "df[\"annotations\"] = df[\"annotations\"].apply(extract_annotation_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, similarly to section 4 above, we loop through each row (of JSON data - contained in `json_data`) and extract the classification_id and annotations for each of them, which we then add on our new DataFrame `df_annotations`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.DataFrame()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    s = pd.Series(row.annotations, name=index)\n",
    "    df_annotations = pd.concat([df_annotations, s], axis=1)\n",
    "    \n",
    "df_annotations = df_annotations.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the `.head()` method again to check our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Zooniverse subjects (`subject_data`)\n",
    "\n",
    "Next, we want to read in the `subjects.csv` file above, so we know what files each of the classifications were done on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects = pd.read_csv(subjects_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at our data using the `.head()` method that we learned above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the classifications, we can see from this preview that the `subject_id` is a column, which is unique for each subject. Similarly to what we did with the classifications above, we can turn it into an \"index\" for the DataFrame, a nice way of querying the frame by individual IDs. Again, here's how we'd do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects.set_index(\"subject_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the preview, there are some quirky aspects of the `subjects.csv` file from Zooniverse. Two things we might want to address here is that the `metadata` column is formatted as embedded JSON data, and so is the `locations` column.\n",
    "\n",
    "The `metadata` column corresponds to the data from any manifest file that you uploaded with your subject sets, so it often contains valuable information for us to have with our classifications.\n",
    "\n",
    "The `locations` column contains the URL to all of the images that each subject links to. For our projects, we might just have one location, but not necessarily: subjects can contain multiple images!\n",
    "\n",
    "For our purposes, we want to create a more readable list of locations and extract the metadata into its own columns. Let's go ahead and do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by making sure that both columns are formatted correctly, as we did with the classifications' metadata and annotations above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects[\"metadata\"] = df_subjects[\"metadata\"].apply(json.loads)\n",
    "df_subjects[\"locations\"] = df_subjects[\"locations\"].apply(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the `locations` column. Since the data is structured as a Python dictionary `{id: \"URL\"}`, we can get a list of all the URLs by using Python's `dict` type's built-in `.values()` method. Here, we put that method into a custom function, which takes any row from the `subjects` DataFrame, makes a list from its values, and then joins them together with a comma separation (see the `\", \".join()` syntax):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locations_as_list(row):\n",
    "    return \", \".join(list(row.values()))\n",
    "\n",
    "df_subjects[\"locations_list\"] = df_subjects[\"locations\"].apply(locations_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to save some space, we can remove the old `locations` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects = df_subjects.drop([\"locations\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will turn to the subjects' `metadata` column.\n",
    "\n",
    "Similarly to the extraction of classifications metadata above, we will create a separate DataFrame from the normalised JSON data from the subjects column using the `json_normalize` method and then use `.head()` to see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects_metadata = pd.json_normalize(df_subjects[\"metadata\"])\n",
    "\n",
    "df_subjects_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, since we know that the shape of the subjects' metadata DataFrame (`df_subjects_metadata`) and the main subject DataFrame (`df_subject`) are the same, we can apply the `set_index` method to the metadata to get the `subject_id` as index on the `df_subjects_metadata`.\n",
    "\n",
    "After, we'll run the `.head()` reality check, to make sure all is well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects_metadata.set_index(df_subjects.index, inplace=True)\n",
    "\n",
    "df_subjects_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've now extracted the `metadata` column into a separate DataFrame, let's go ahead and remove the column from the original or \"main\" `df_subjects` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects = df_subjects.drop(\"metadata\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A really great feature of DataFrames is that you can join them back together, as long as the `pandas` library has an easy way of matching the two DataFrames (or more!) together. A joined index, such as we have for `df_subjects` and `df_subjects_metadata` is a great way to do so.\n",
    "\n",
    "In order to get one large `df_subjects` DataFrame that contains all the data for each subject, we can thus run the `.join` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects = df_subjects.join(df_subjects_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see that `pandas` succeeds silently, so let's do a reality check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is one large (but handy) DataFrame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining all the data back together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final step, we want to join the data back together into a new main DataFrame, `df_final`, from which we will remove all the personal data so the dataset can be shared publicly, if we want.\n",
    "\n",
    "To recap, here are the four DataFrames that we have created thus far:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main DataFrame (`df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subjects DataFrame (`df_subjects`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata DataFrame (`df_metadata`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotations DataFrame (`df_annotations`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the summary above, of the main DataFrame (`df`), it now doubles the information in `df_subjects`, `df_metadata`, and `df_annotations`. So before we do anything else, we will drop the columns that we have now processed from `df` to reduce the size of `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"subject_data\", \"metadata\", \"annotations\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redact personal information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to ensure that we have anonymised the user data.\n",
    "\n",
    "Here, we have created our own function, `redact_username`, which uses a cryptographic hash method from Python's built-in `hashlib` library called `sha256`. You can read more about [the algorithm's history on Wikipedia](https://en.wikipedia.org/wiki/SHA-2) if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_username(row):\n",
    "    return hashlib.sha256(str(row).encode()).hexdigest() if not pd.isna(row) else None\n",
    "    \n",
    "df[\"user_name_redacted\"] = df[\"user_name\"].apply(redact_username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also be interested in knowing whether a user was logged in or not when they annotated the subject. In order to preserve that information, we create another custom function, `user_was_logged_in`, which uses the information from the `user_name` column (which has a value like `not-logged-in-98ff168ef257e2fd9d4a` if the user was not logged in) to extract a `True` or `False` value (also called a \"boolean\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_was_logged_in(row):\n",
    "    return \"not-logged-in\" not in row if not pd.isna(row) else False\n",
    "\n",
    "df[\"user_logged_in\"] = df[\"user_name\"].apply(user_was_logged_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to drop columns that contain personal identifying information - usernames, IDs and IP addresses - from the main DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"user_id\", \"user_name\", \"user_ip\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all the data\n",
    "\n",
    "Now, it's time to join all the DataFrames into one new `df_final` frame.\n",
    "\n",
    "Adding the metadata and the annotations on the main `df` is an easy thing, since all of them share index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.join(df_metadata).join(df_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick reality check to make sure that all the data is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good. But now we want to join our subjects on the `df_final` table as well. It's not entirely as easy as the previous multiple join task that we just did here.\n",
    "\n",
    "This time, because we're not using data points that are uniquely connected, one-to-one (one subject, in fact, will have many classifications), we will end up with duplicated information in the table. In order to join the main DataFrame with the subject DataFrame `df_subjects`, we need to make one intermediary step: We need to make both index columns available in each of the DataFrames.\n",
    "\n",
    "_Why do we need to make `df_final`'s index a column?_ We will _merge_ two DataFrames, which is a function that will discard both indices of the merging DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects[\"subject_ids\"] = df_subjects.index\n",
    "df_final[\"classification_id\"] = df_final.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the merge, we also want to make sure that the two matching columns on both DataFrames are of the same (correct) type—otherwise Pandas will have trouble finding the matching subject row for each classification.\n",
    "\n",
    "For that, we use the built-in method on each DataFrame, `.astype()` which \"casts\" a column as a type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects[\"subject_ids\"] = df_subjects[\"subject_ids\"].astype(int)\n",
    "df_final[\"subject_ids\"] = df_final[\"subject_ids\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to use the `merge` function from Pandas central library to join the two on the column that is shared between the two DataFrames (in our case `subject_ids`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_final, df_subjects, on=\"subject_ids\", how=\"left\", suffixes=(\"_classification\", \"_subject\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can make the `classification_id` column an index again, on our final DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.set_index(\"classification_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last reality check, before we're ready to export!\n",
    "\n",
    "This time, however, we set the max column to be displayed to `None` because we're interested in seeing all the columns. Then we use our now familiar `.head()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export!\n",
    "\n",
    "In this final step, we can export the file to whatever format that we'd like to use.\n",
    "\n",
    "In the case below, we opt for `.csv`, which is a common, open file format that can be easily opened in Microsoft Excel for further processing. It can also be imported into visualisation software, such as Power BI, or websites like ObservableHQ. On Colab, the file will be stored in a temporary directory. Once you've run the code below, click the 'folder' icon to view it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"combined_zooniverse_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
